[{"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Python", "code": "\nWorks with: Python version 2.5Works with: Python version 3.0\ntext = \"Hello,How,Are,You,Today\"\ntokens = text.split(',')\nprint ('.'.join(tokens))\n\nprint ('.'.join('Hello,How,Are,You,Today'.split(',')))\n", "explain": "Or if interpretation of the task description means you don't need to keep an intermediate array:\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "C", "code": "\nWorks with: ANSI C\nLibrary: POSIX\n\n#include<string.h>\n#include<stdio.h>\n#include<stdlib.h>\n\nint main(void)\n{\n\tchar *a[5];\n\tconst char *s=\"Hello,How,Are,You,Today\";\n\tint n=0, nn;\n\n\tchar *ds=strdup(s);\n\n\ta[n]=strtok(ds, \",\");\n\twhile(a[n] && n<4) a[++n]=strtok(NULL, \",\");\n\n\tfor(nn=0; nn<=n; ++nn) printf(\"%s.\", a[nn]);\n\tputchar('\\n');\n\n\tfree(ds);\n\n\treturn 0;\n}\n\n\n#include<stdio.h>\n\ntypedef void (*callbackfunc)(const char *);\n\nvoid doprint(const char *s) {\n\tprintf(\"%s.\", s);\n}\n\nvoid tokenize(char *s, char delim, callbackfunc cb) {\n\tchar *olds = s;\n\tchar olddelim = delim;\n\twhile(olddelim && *s) {\n\t\twhile(*s && (delim != *s)) s++;\n\t\t*s ^= olddelim = *s; // olddelim = *s; *s = 0;\n\t\tcb(olds);\n\t\t*s++ ^= olddelim; // *s = olddelim; s++;\n\t\tolds = s;\n\t}\n}\n\nint main(void)\n{\n        char array[] = \"Hello,How,Are,You,Today\";\n\ttokenize(array, ',', doprint);\n\treturn 0;\n}\n\n", "explain": "This example uses the strtok() function to separate the tokens. This function is destructive (replacing token separators with '\\0'), so we have to make a copy of the string (using strdup()) before tokenizing. strdup() is not part of ANSI C, but is available on most platforms. It can easily be implemented with a combination of strlen(), malloc(), and strcpy().\nAnother way to accomplish the task without the built-in string functions is to temporarily modify the separator character. This method does not need any additional memory, but requires the input string to be writeable.\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "C++", "code": "\nWorks with: C++98\n\n#include <string>\n#include <sstream>\n#include <vector>\n#include <iterator>\n#include <iostream>\n#include <algorithm>\nint main()\n{\n    std::string s = \"Hello,How,Are,You,Today\";\n    std::vector<std::string> v;\n    std::istringstream buf(s);\n    for(std::string token; getline(buf, token, ','); )\n        v.push_back(token);\n    copy(v.begin(), v.end(), std::ostream_iterator<std::string>(std::cout, \".\"));\n    std::cout << '\\n';\n}\n\nWorks with: C++98\n\n#include <string>\n#include <locale>\n#include <sstream>\n#include <vector>\n#include <iterator>\n#include <iostream>\n#include <algorithm>\nstruct comma_ws : std::ctype<char> {\n    static const mask* make_table() {\n    static std::vector<mask> v(classic_table(), classic_table() + table_size);\n        v[','] |= space;  // comma will be classified as whitespace\n        return &v[0];\n    }\n    comma_ws(std::size_t refs = 0) : ctype<char>(make_table(), false, refs) {}\n};\nint main()\n{\n    std::string s = \"Hello,How,Are,You,Today\";\n    std::istringstream buf(s);\n    buf.imbue(std::locale(buf.getloc(), new comma_ws));\n    std::istream_iterator<std::string> beg(buf), end;\n    std::vector<std::string> v(beg, end);\n    copy(v.begin(), v.end(), std::ostream_iterator<std::string>(std::cout, \".\"));\n    std::cout << '\\n';\n}\n\nWorks with: C++98\nLibrary: boost\n\n#include <string>\n#include <vector>\n#include <iterator>\n#include <algorithm>\n#include <iostream>\n#include <boost/tokenizer.hpp>\nint main()\n{\n    std::string s = \"Hello,How,Are,You,Today\";\n    boost::tokenizer<> tok(s);\n    std::vector<std::string> v(tok.begin(), tok.end());\n    copy(v.begin(), v.end(), std::ostream_iterator<std::string>(std::cout, \".\"))\n    std::cout << '\\n';\n}\n\nWorks with: C++23\n\n#include <string>\n#include <ranges>\n#include <iostream>\nint main() {\n    std::string s = \"Hello,How,Are,You,Today\";\n    s = s                               // Assign the final string back to the string variable\n      | std::views::split(',')          // Produce a range of the comma separated words\n      | std::views::join_with('.')      // Concatenate the words into a single range of characters\n      | std::ranges::to<std::string>(); // Convert the range of characters into a regular string\n    std::cout << s;\n}\n\n", "explain": "std::getline() is typically used to tokenize strings on a single-character delimiter\nC++ allows the user to redefine what is considered whitespace. If the delimiter is whitespace, tokenization becomes effortless.\nThe boost library has multiple options for easy tokenization.\nC++20 and C++23 drastically improve the ergonomics of simple manipulation of ranges.\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Java", "code": "\nWorks with: Java version 1.0+\n\nWorks with: Java version 1.8+\nString toTokenize = \"Hello,How,Are,You,Today\";\nSystem.out.println(String.join(\".\", toTokenize.split(\",\")));\n\nWorks with: Java version 1.4+\nString toTokenize = \"Hello,How,Are,You,Today\";\n\nString words[] = toTokenize.split(\",\");//splits on one comma, multiple commas yield multiple splits\n               //toTokenize.split(\",+\") if you want to ignore empty fields\nfor(int i=0; i<words.length; i++) {\n    System.out.print(words[i] + \".\");\n}\n\n\nWorks with: Java version 1.0+\nString toTokenize = \"Hello,How,Are,You,Today\";\n\nStringTokenizer tokenizer = new StringTokenizer(toTokenize, \",\");\nwhile(tokenizer.hasMoreTokens()) {\n    System.out.print(tokenizer.nextToken() + \".\");\n}\n\n", "explain": "There are multiple ways to tokenize a String in Java.\nThe first is by splitting the String into an array of Strings. The separator is actually a regular expression so you could do very powerful things with this, but make sure to escape any characters with special meaning in regex.\nThe other way is to use StringTokenizer. It will skip any empty tokens. So if two commas are given in line, there will be an empty string in the array given by the split function, but no empty string with the StringTokenizer object. This method takes more code to use, but allows you to get tokens incrementally instead of all at once.\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "C#", "code": "\nstring str = \"Hello,How,Are,You,Today\"; \n// or Regex.Split ( \"Hello,How,Are,You,Today\", \",\" );\n// (Regex is in System.Text.RegularExpressions namespace)\nstring[] strings = str.Split(',');\nConsole.WriteLine(String.Join(\".\", strings));\n\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "JavaScript", "code": "\nWorks with: Firefox version 2.0\nalert( \"Hello,How,Are,You,Today\".split(\",\").join(\".\") );\n\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "PHP", "code": "\nWorks with: PHP version 5.x\n<?php\n$str = 'Hello,How,Are,You,Today';\necho implode('.', explode(',', $str));\n?>\n\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Fortran", "code": "\nWorks with: Fortran version 90 and later\nPROGRAM Example\n\n  CHARACTER(23) :: str = \"Hello,How,Are,You,Today\"\n  CHARACTER(5) :: word(5)\n  INTEGER :: pos1 = 1, pos2, n = 0, i\n\n  DO\n    pos2 = INDEX(str(pos1:), \",\")\n    IF (pos2 == 0) THEN\n       n = n + 1\n       word(n) = str(pos1:)\n       EXIT\n    END IF\n    n = n + 1\n    word(n) = str(pos1:pos1+pos2-2)\n    pos1 = pos2+pos1\n END DO\n\n DO i = 1, n\n   WRITE(*,\"(2A)\", ADVANCE=\"NO\") TRIM(word(i)), \".\"\n END DO\n \nEND PROGRAM Example\n\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Go", "code": "\npackage main\n\nimport (\n    \"fmt\"\n    \"strings\"\n)\n\nfunc main() {\n    s := \"Hello,How,Are,You,Today\"\n    fmt.Println(strings.Join(strings.Split(s, \",\"), \".\"))\n}\n\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "ARM_Assembly", "code": "\nWorks with: as version Raspberry Pi\n/* ARM assembly Raspberry PI  */\n/*  program strTokenize.s   */\n\n/* Constantes    */\n.equ STDOUT, 1                          @ Linux output console\n.equ EXIT,   1                           @ Linux syscall\n.equ WRITE,  4                           @ Linux syscall\n\n.equ NBPOSTESECLAT,          20\n\n/* Initialized data */\n.data\nszMessFinal:   .asciz \"Words are\u00a0: \\n\"\n\nszString:            .asciz \"Hello,How,Are,You,Today\"\nszMessError:         .asciz \"Error tokenize\u00a0!!\\n\"\nszCarriageReturn:   .asciz \"\\n\"\n\n/* UnInitialized data */\n.bss \n\n/*  code section */\n.text\n.global main \nmain: \n    ldr r0,iAdrszString                           @ string address \n    mov r1,#','                                   @ separator\n    bl stTokenize\n    cmp r0,#-1                                    @ error\u00a0?\n    beq 99f\n    mov r2,r0                                     @ table address\n    ldr r0,iAdrszMessFinal                        @ display message\n    bl affichageMess\n    ldr r4,[r2]                                   @ number of areas\n    add r2,#4                                     @ first area\n    mov r3,#0                                     @ loop counter\n1:                                                @ display loop \n    ldr r0,[r2,r3, lsl #2]                        @ address area\n    bl affichageMess\n    ldr r0,iAdrszCarriageReturn                   @ display carriage return\n    bl affichageMess\n    add r3,#1                                     @ counter + 1\n    cmp r3,r4                                     @ end\u00a0?\n    blt 1b                                        @ no -> loop\n\n    b 100f\n99:                                               @ display error message\n    ldr r0,iAdrszMessError\n    bl affichageMess\n\n100:                                              @ standard end of the program\n    mov r0, #0                                    @ return code\n    mov r7, #EXIT                                 @ request to exit program\n    svc 0                                         @ perform the system call\niAdrszString:             .int szString\niAdrszFinalString:       .int szFinalString\niAdrszMessFinal:          .int szMessFinal\niAdrszMessError:          .int szMessError\niAdrszCarriageReturn:    .int szCarriageReturn\n/******************************************************************/\n/*     display text with size calculation                         */ \n/******************************************************************/\n/* r0 contains the address of the message */\naffichageMess:\n    push {r0,r1,r2,r7,lr}                       @ save  registers \n    mov r2,#0                                   @ counter length */\n1:                                              @ loop length calculation\n    ldrb r1,[r0,r2]                             @ read octet start position + index \n    cmp r1,#0                                   @ if 0 its over\n    addne r2,r2,#1                              @ else add 1 in the length\n    bne 1b                                      @ and loop \n                                                @ so here r2 contains the length of the message \n    mov r1,r0                                   @ address message in r1 \n    mov r0,#STDOUT                              @ code to write to the standard output Linux\n    mov r7, #WRITE                              @ code call system \"write\" \n    svc #0                                      @ call systeme\n    pop {r0,r1,r2,r7,lr}                        @ restaur des  2 registres\n    bx lr                                       @ return\n/*******************************************************************/\t   \n/* Separate string by separator into an array                     */\n/* areas are store on the heap Linux                               */\n/*******************************************************************/\t  \n/* r0 contains string address */\n/* r1 contains separator character (, or . or\u00a0: )    */\n/* r0 returns table address with first item = number areas */\n/* and other items contains pointer of each string     */\nstTokenize:\n    push {r1-r8,lr}                                 @ save des registres\n    mov r6,r0\n    mov r8,r1                                       @ save separator\n    bl strLength                                    @ length string for place reservation on the heap\n    mov r4,r0\n    ldr r5,iTailleTable\n    add r5,r0\n    and r5,#0xFFFFFFFC\n    add r5,#4                                       @ align word on the heap\n                                                    @ place reservation on the heap \n    mov r0,#0                                       @ heap address\n    mov r7, #0x2D                                   @ call system linux 'brk'\n    svc #0                                          @ call system\n    cmp r0,#-1                                      @ error call system\n    beq 100f\n    mov r3,r0                                       @ save address  heap begin\n    add r0,r5                                       @ reserve r5 byte on the heap\n    mov r7, #0x2D                                   @ call system linux 'brk'\n    svc #0\n    cmp r0,#-1\n    beq 100f\n                                                    @ string copy on the heap\n    mov r0,r6\n    mov r1,r3\n1:                                                  @ loop copy string\n    ldrb r2,[r0],#1                                 @ read one byte and increment pointer one byte\n    strb r2,[r1],#1                                 @ store one byte and increment pointer one byte\n    cmp r2,#0                                       @ end of string\u00a0?\n    bne 1b                                          @ no -> loop \n\n    add r4,r3                                        @ r4 contains address table begin\n    mov r0,#0\n    str r0,[r4]\n    str r3,[r4,#4]\n    mov r2,#1                                       @ areas counter\n2:                                                  @ loop load string character \n    ldrb r0,[r3]\n    cmp r0,#0\n    beq 3f                                          @ end string \n    cmp r0,r8                                       @ separator\u00a0?\n    addne r3,#1                                     @ no -> next location \n    bne 2b                                          @ and loop\n    mov r0,#0                                       @ store zero final of string\n    strb r0,[r3]\n    add r3,#1                                       @ next character\n    add r2,#1                                       @ areas counter + 1\n    str r3,[r4,r2, lsl #2]                          @ store address area in the table at index r2\n    b 2b                                            @ and loop\n \n3:\n    str r2,[r4]                                     @ returns number areas\n    mov r0,r4\n100:\n    pop {r1-r8,lr}\n    bx lr\niTailleTable: .int 4 * NBPOSTESECLAT\n/***************************************************/\n/*   calcul size string                            */\n/***************************************************/\n/* r0 string address                 */\n/* r0 returns size string            */\nstrLength:\n    push {r1,r2,lr}\n    mov r1,#0                                           @ init counter\n1:\n   ldrb r2,[r0,r1]                                      @ load byte of string index r1\n   cmp r2,#0                                            @ end string\u00a0?\n   addne r1,#1                                          @ no -> +1 counter\n   bne 1b                                               @ and loop\n\n100:\n    mov r0,r1\n    pop {r1,r2,lr}\n    bx lr\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Delphi", "code": "\nUsing String.split[edit]\nLibrary:  System.SysUtils\nprogram Tokenize_a_string;\n\n{$APPTYPE CONSOLE}\n\nuses\n  System.SysUtils;\n\nvar\n  Words: TArray<string>;\n\nbegin\n  Words := 'Hello,How,Are,You,Today'.Split([',']);\n  Writeln(string.Join(#10, Words));\n\n  Readln;\nend.\n\nUsing TStringList[edit]\nprogram TokenizeString;\n\n{$APPTYPE CONSOLE}\n\nuses\n  Classes;\n\nvar\n  tmp: TStringList;\n  i: Integer;\n\nbegin\n\n  // Instantiate TStringList class\n  tmp := TStringList.Create;\n  try\n    { Use the TStringList's CommaText property to get/set\n      all the strings in a single comma-delimited string }\n    tmp.CommaText := 'Hello,How,Are,You,Today';\n\n    { Now loop through the TStringList and display each\n      token on the console }\n    for i := 0 to Pred(tmp.Count) do\n      Writeln(tmp[i]);\n\n  finally\n    tmp.Free;\n  end;\n\n  Readln;\n\nend.\n\n\nHello\nHow\nAre\nYou\nToday\n\n", "explain": "The result is:\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Ruby", "code": "\nputs \"Hello,How,Are,You,Today\".split(',').join('.')\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Rust", "code": "\nfn main() {\n    let s = \"Hello,How,Are,You,Today\";\n    let tokens: Vec<&str> = s.split(\",\").collect();\n    println!(\"{}\", tokens.join(\".\"));\n}\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Swift", "code": "\nWorks with: Swift version 3.x\nlet text = \"Hello,How,Are,You,Today\"\nlet tokens = text.components(separatedBy: \",\") // for single or multi-character separator\nprint(tokens)\nlet result = tokens.joined(separator: \".\")\nprint(result)\nWorks with: Swift version 2.x\nlet text = \"Hello,How,Are,You,Today\"\nlet tokens = text.characters.split(\",\").map{String($0)} // for single-character separator\nprint(tokens)\nlet result = tokens.joinWithSeparator(\".\")\nprint(result)\nWorks with: Swift version 1.x\nlet text = \"Hello,How,Are,You,Today\"\nlet tokens = split(text, { $0 == \",\" }) // for single-character separator\nprintln(tokens)\nlet result = \".\".join(tokens)\nprintln(result)\nFor multi-character separators:import Foundation\n\nlet text = \"Hello,How,Are,You,Today\"\nlet tokens = text.componentsSeparatedByString(\",\")\nprint(tokens)\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "R", "code": "\ntext <- \"Hello,How,Are,You,Today\"\njunk <- strsplit(text, split=\",\")\nprint(paste(unlist(junk), collapse=\".\"))\n\npaste(unlist(strsplit(text, split=\",\")), collapse=\".\")\n", "explain": "or the one liner\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "COBOL", "code": "\n\n      identification division.\n       program-id. tokenize.\n\n       environment division.\n       configuration section.\n       repository.\n           function all intrinsic.\n\n       data division.\n       working-storage section.\n       01 period constant as \".\".\n       01 cmma   constant as \",\".\n\n       01 start-with.\n          05 value \"Hello,How,Are,You,Today\".\n\n       01 items.\n          05 item pic x(6) occurs 5 times.\n\n       procedure division.\n       tokenize-main.\n       unstring start-with delimited by cmma\n           into item(1) item(2) item(3) item(4) item(5)\n\n       display trim(item(1)) period trim(item(2)) period\n               trim(item(3)) period trim(item(4)) period\n               trim(item(5))\n\n       goback.\n       end program tokenize.\n\n\nOutput:\nprompt$ cobc -xj tokenize.cob\nHello.How.Are.You.Today\n\n", "explain": "This can be made to handle more complex cases; UNSTRING allows multiple delimiters, capture of which delimiter was used for each field, a POINTER for starting position (set on ending), along with match TALLYING.\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Ada", "code": "\nwith Ada.Text_IO, Ada.Containers.Indefinite_Vectors, Ada.Strings.Fixed, Ada.Strings.Maps;\nuse Ada.Text_IO, Ada.Containers, Ada.Strings, Ada.Strings.Fixed, Ada.Strings.Maps;\n\nprocedure Tokenize is\n   package String_Vectors is new Indefinite_Vectors (Positive, String);\n   use String_Vectors;\n   Input  : String   := \"Hello,How,Are,You,Today\";\n   Start  : Positive := Input'First;\n   Finish : Natural  := 0;\n   Output : Vector   := Empty_Vector;\nbegin\n   while Start <= Input'Last loop\n      Find_Token (Input, To_Set (','), Start, Outside, Start, Finish);\n      exit when Start > Finish;\n      Output.Append (Input (Start .. Finish));\n      Start := Finish + 1;\n   end loop;\n   for S of Output loop\n      Put (S & \".\");\n   end loop;\nend Tokenize;\n\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Julia", "code": "\ns = \"Hello,How,Are,You,Today\"\na = split(s, \",\")\nt = join(a, \".\")\n\nprintln(\"The string \\\"\", s, \"\\\"\")\nprintln(\"Splits into \", a)\nprintln(\"Reconstitutes to \\\"\", t, \"\\\"\")\n\n\nOutput:\nThe string \"Hello,How,Are,You,Today\"\nSplits into SubString{ASCIIString}[\"Hello\",\"How\",\"Are\",\"You\",\"Today\"]\nReconstitutes to \"Hello.How.Are.You.Today\"\n\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Kotlin", "code": "\nWorks with: Kotlin version 1.0b4\nfun main(args: Array<String>) {\n    val input = \"Hello,How,Are,You,Today\"\n    println(input.split(',').joinToString(\".\"))\n}\n\n\nOutput:\nHello.How.Are.You.Today\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Perl", "code": "\nprint join('.', split /,/, 'Hello,How,Are,You,Today'), \"\\n\";\n\n\necho \"Hello,How,Are,You,Today\" | perl -aplF/,/ -e '$\" = \".\"; $_ = \"@F\";'\n\n\nBEGIN { $/ = \"\\n\"; $\\ = \"\\n\"; }\nLINE: while (defined($_ = <ARGV>)) {\n    chomp $_;\n    our(@F) = split(/,/, $_, 0);\n    $\" = '.';\n    $_ = \"@F\";\n}\ncontinue {\n    die \"-p destination: $!\\n\" unless print $_;\n}\n\n", "explain": "CLI one-liner form:\nwhich is a compact way of telling Perl to do\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Objective-C", "code": "\nWorks with: GNUstep\nWorks with: Cocoa\nNSString *text = @\"Hello,How,Are,You,Today\";\nNSArray *tokens = [text componentsSeparatedByString:@\",\"];\nNSString *result = [tokens componentsJoinedByString:@\".\"];\nNSLog(result);\n\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Prolog", "code": "\nWorks with: SWI Prolog\nsplitup(Sep,[token(B)|BL]) --> splitup(Sep,B,BL).\nsplitup(Sep,[A|AL],B)      --> [A], {\\+ [A] = Sep }, splitup(Sep,AL,B).\nsplitup(Sep,[],[B|BL])     --> Sep, splitup(Sep,B,BL).\nsplitup(_Sep,[],[])        --> [].\nstart\u00a0:-\n    phrase(splitup(\",\",Tokens),\"Hello,How,Are,You,Today\"),\n    phrase(splitup(\".\",Tokens),Backtogether),\n    string_to_list(ABack,Backtogether),\n    writeln(ABack).\n\nOutput:\n\u00a0?- start.\n Hello.How.Are.You.Today\n\nWorks with: SWI Prolog 7\n\n?- split_string(\"Hello,How,Are,You,Today\", \",\", \"\", Split),\n|    atomics_to_string(Split, \".\", PeriodSeparated),\n|    writeln(PeriodSeparated).\nHello.How.Are.You.Today\n", "explain": "Using the SWI Prolog string data type and accompanying predicates,\nthis can be accomplished in a few lines in the top level:\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Lua", "code": "\n\nfunction string:split (sep)\n    local sep, fields = sep or \":\", {}\n    local pattern = string.format(\"([^%s]+)\", sep)\n    self:gsub(pattern, function(c) fields[#fields+1] = c end)\n    return fields\nend\n\nlocal str = \"Hello,How,Are,You,Today\"\nprint(table.concat(str:split(\",\"), \".\"))\n\n\nOutput:\nHello.How.Are.You.Today\n", "explain": "Split function callously stolen from the lua-users wiki\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Scala", "code": "\nprintln(\"Hello,How,Are,You,Today\" split \",\" mkString \".\")\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "D", "code": "\nvoid main() {\n    import std.stdio, std.string;\n\n    \"Hello,How,Are,You,Today\".split(',').join('.').writeln;\n}\n\n\nOutput:\nHello.How.Are.You.Today\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Haskell", "code": "\n\n{-# OPTIONS_GHC -XOverloadedStrings #-}\nimport Data.Text (splitOn,intercalate)\nimport qualified Data.Text.IO as T (putStrLn)\n\nmain = T.putStrLn . intercalate \".\" $ splitOn \",\" \"Hello,How,Are,You,Today\"\n\n\nsplitBy :: (a -> Bool) -> [a] -> [[a]]\nsplitBy _ [] = []\nsplitBy f list = first : splitBy f (dropWhile f rest) where\n  (first, rest) = break f list\n\nsplitRegex :: Regex -> String -> [String]\n\njoinWith :: [a] -> [[a]] -> [a]\njoinWith d xs = concat $ List.intersperse d xs\n-- \"concat $ intersperse\" can be replaced with \"intercalate\" from the Data.List in GHC 6.8 and later\n\nputStrLn $ joinWith \".\" $ splitBy (== ',') $ \"Hello,How,Are,You,Today\"\n\n-- using regular expression to split:\nimport Text.Regex\nputStrLn $ joinWith \".\" $ splitRegex (mkRegex \",\") $ \"Hello,How,Are,You,Today\"\n\n\n*Main> mapM_ putStrLn $ takeWhile (not.null) $ unfoldr (Just . second(drop 1). break (==',')) \"Hello,How,Are,You,Today\"\nHello\nHow\nAre\nYou\nToday\n\nYou need to import the modules Data.List and Control.Arrow\n\n", "explain": "Using Data.Text\nOutput: Hello.How.Are.You.Today\nAlternate Solution\nThe necessary operations are unfortunately not in the standard library (yet), but simple to write:\nTokenizing can also be realized by using unfoldr and break:\nAs special cases, splitting / joining by white space and by newlines are provided by the Prelude functions words / unwords and lines / unlines, respectively.\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "VBScript", "code": "\nOne liner[edit]\nWScript.Echo Join(Split(\"Hello,How,Are,You,Today\", \",\"), \".\")\n\n\nVisual Basic[edit]\nTranslation of: PowerBASIC\n\nSub Main()\n    Dim parseMe As String, parsed As Variant\n    parseMe = \"Hello,How,Are,You,Today\"\n\n    parsed = Split(parseMe, \",\")\n\n    Dim L0 As Long, outP As String\n    outP = parsed(0)\n    For L0 = 1 To UBound(parsed)\n        outP = outP & \".\" & parsed(L0)\n    Next\n\n    MsgBox outP\nEnd Sub\n\n", "explain": "In fact, the Visual Basic solution (below) could have done the same, as Join() is available.\nUnlike PowerBASIC, there is no need to know beforehand how many tokens are in the string -- Split automagically builds the array for you.\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Scheme", "code": "\nWorks with: Guile\n(use-modules (ice-9 regex))\n(define s \"Hello,How,Are,You,Today\")\n(define words (map match:substring (list-matches \"[^,]+\" s)))\n\n(do ((n 0 (+ n 1))) ((= n (length words)))\n        (display (list-ref words n))\n        (if (< n (- (length words) 1))\n                (display \".\")))\n\n(define s \"Hello,How,Are,You,Today\")\n(define words (string-tokenize s (char-set-complement (char-set #\\,))))\n(define t (string-join words \".\"))\nWorks with: Gauche Scheme\n(print\n  (string-join\n    (string-split \"Hello,How,Are,You,Today\" #\\,)\n    \".\"))\n\nOutput:\nHello.How.Are.You.Today\n\n", "explain": "(with SRFI 13)\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "PowerShell", "code": "\nWorks with: PowerShell version 1\n$words = \"Hello,How,Are,You,Today\".Split(',')\n[string]::Join('.', $words)\nWorks with: PowerShell version 2\n$words = \"Hello,How,Are,You,Today\" -split ','\n$words -join '.'\nWorks with: PowerShell version 2\n\n\"Hello,How,Are,You,Today\", \",,Hello,,Goodbye,,\" | ForEach-Object {($_.Split(',',[StringSplitOptions]::RemoveEmptyEntries)) -join \".\"}\n\nOutput:\nHello.How.Are.You.Today\nHello.Goodbye\n\n", "explain": "The StringSplitOptions enumeration weeds out the return of empty elements. \n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Logo", "code": "\nWorks with: UCB Logo\nto split :str :sep\n  output parse map [ifelse\u00a0? = :sep [\"| |] [?]] :str\nend\n\nto split :str :by [:acc []] [:w \"||]\n  if empty? :str [output lput :w :acc]\n  ifelse equal? first :str :by ~\n    [output (split butfirst :str :by lput :w :acc)] ~\n    [output (split butfirst :str :by         :acc  lput first :str :w)]\nend\n? show split \"Hello,How,Are,You,Today \",\n[Hello How Are You Today]\n", "explain": "This form is more robust, doing the right thing if there are embedded spaces.\n"}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "ColdFusion", "code": "\nClassic tag based CFML[edit]\n<cfoutput>\n  <cfset wordListTag = \"Hello,How,Are,You,Today\">\n  #Replace( wordListTag, \",\", \".\", \"all\" )#\n</cfoutput>\n\n\nOutput:\n\"Hello.How.Are.You.Today\"\n\nScript Based CFML[edit]\n<cfscript>\n  wordList = \"Hello,How,Are,You,Today\";\n  splitList = replace( wordList, \",\", \".\", \"all\" );\n  writeOutput( splitList );\n</cfscript>\n\n\nOutput:\n\"Hello.How.Are.You.Today\"\n\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "F#", "code": "\nSystem.String.Join(\".\", \"Hello,How,Are,You,Today\".Split(','))\n\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Groovy", "code": "\nprintln 'Hello,How,Are,You,Today'.split(',').join('.')\n\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "Zig", "code": "\nconst std = @import(\"std\");\npub fn main() void {\n  const string = \"Hello,How,Are,You,Today\";\n  var tokens = std.mem.split(u8, string, \",\");\n  std.debug.print(\"{s}\", .{tokens.next().?});\n  while (tokens.next()) |token| {\n    std.debug.print(\".{s}\", .{token});\n  }\n}\n", "explain": ""}, {"task_name": "Tokenize a string", "task_url": "https://rosettacode.org/wiki/Tokenize_a_string", "task_cat": "String manipulation", "lang": "AWK", "code": "\nBEGIN {\n  s = \"Hello,How,Are,You,Today\"\n  split(s, arr, \",\")\n  for(i=1; i < length(arr); i++) {\n    printf arr[i] \".\"\n  }\n  print\n}\n\n\nBEGIN { FS = \",\" }\n{\n  for(i=1; i <= NF; i++) printf $i \".\";\n  print \"\"\n}\n\n\n", "explain": "A more idiomatic way for AWK is\nwhich \"tokenize\" each line of input and this is achieved by using \",\" as field separator\n"}]