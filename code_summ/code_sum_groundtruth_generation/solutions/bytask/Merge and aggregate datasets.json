[{"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "Python", "code": "\nPython: Using pandas library[edit]\n# to install pandas library go to cmd prompt and type:\n# cd %USERPROFILE%\\AppData\\Local\\Programs\\Python\\Python38-32\\Scripts\\\n# pip install pandas\nimport pandas as pd\n\n# load data from csv files\ndf_patients = pd.read_csv (r'patients.csv', sep = \",\", decimal=\".\")\ndf_visits = pd.read_csv (r'visits.csv', sep = \",\", decimal=\".\")\n\n''' # load data hard coded, create data frames\nimport io\nstr_patients = \"\"\"PATIENT_ID,LASTNAME\n1001,Hopper\n4004,Wirth\n3003,Kemeny\n2002,Gosling\n5005,Kurtz\n\"\"\"\ndf_patients = pd.read_csv(io.StringIO(str_patients), sep = \",\", decimal=\".\")\nstr_visits = \"\"\"PATIENT_ID,VISIT_DATE,SCORE\n2002,2020-09-10,6.8\n1001,2020-09-17,5.5\n4004,2020-09-24,8.4\n2002,2020-10-08,\n1001,,6.6\n3003,2020-11-12,\n4004,2020-11-05,7.0\n1001,2020-11-19,5.3\n\"\"\"\ndf_visits = pd.read_csv(io.StringIO(str_visits), sep = \",\", decimal=\".\")\n'''\n\n# typecast from string to datetime so .agg can 'max' it\ndf_visits['VISIT_DATE'] = pd.to_datetime(df_visits['VISIT_DATE'])\n\n# merge on PATIENT_ID\ndf_merge = df_patients.merge(df_visits, on='PATIENT_ID', how='left')\n\n# groupby is an intermediate object\ndf_group = df_merge.groupby(['PATIENT_ID','LASTNAME'], as_index=False)\n\n# note: you can use 'sum' instead of the lambda function but that returns NaN as 0 (zero)\ndf_result = df_group.agg({'VISIT_DATE': 'max', 'SCORE': [lambda x: x.sum(min_count=1),'mean']})\n\nprint(df_result)\n\n  PATIENT_ID LASTNAME LAST_VISIT      SCORE\n                             max <lambda_0> mean\n0       1001   Hopper 2020-11-19       17.4  5.8\n1       2002  Gosling 2020-10-08        6.8  6.8\n2       3003   Kemeny 2020-11-12        NaN  NaN\n3       4004    Wirth 2020-11-05       15.4  7.7\n4       5005    Kurtz        NaT        NaN  NaN\n\nPython: Stdlib csv only[edit]\n\nimport csv\n\nfnames = 'patients.csv  patients_visits.csv'.split()\n\ndef csv2list(fname):\n    with open(fname) as f:\n        rows = list(csv.reader(f))\n    return rows\n\npatients, visits = data = [csv2list(fname) for fname in fnames]\nresult = [record.copy() for record in patients]\nresult[1:] = sorted(result[1:])\n#%%\nresult[0].append('LAST_VISIT')\nlast = {p: vis for p, vis, *score in visits[1:]}\nfor record in result[1:]:\n    p = record[0]\n    record.append(last.get(p, ''))\n#%%\nresult[0] += ['SCORE_SUM', 'SCORE_AVG']\nn = {p: 0 for p, *_ in patients[1:]}\ntot = n.copy()\nfor record in visits[1:]:\n    p, _, score = record\n    if score:\n        n[p] += 1\n        tot[p] += float(score)\nfor record in result[1:]:\n    p = record[0]\n    if n[p]:\n        record += [f\"{tot[p]:5.1f}\", f\"{tot[p] / n[p]:5.2f}\"]\n    else:\n        record += ['', '']\n#%%\nfor record in result:\n    print(f\"| {' | '.join(f'{r:^10}' for r in record)} |\")\n\n\nOutput:\n| PATIENT_ID |  LASTNAME  | LAST_VISIT | SCORE_SUM  | SCORE_AVG  |\n|    1001    |   Hopper   | 2020-11-19 |    17.4    |    5.80    |\n|    2002    |  Gosling   | 2020-10-08 |     6.8    |    6.80    |\n|    3003    |   Kemeny   | 2020-11-12 |            |            |\n|    4004    |   Wirth    | 2020-11-05 |    15.4    |    7.70    |\n|    5005    |   Kurtz    |            |            |            |\n\nPython: Stdlib sqlite3 and csv only[edit]\n\nimport sqlite3\nimport csv\n\n\nfnames = 'patients.csv  patients_visits.csv'.split()\nconn = sqlite3.connect(\":memory:\")\n#%%\n    \ndef create_table_headers(conn):\n    curs = conn.cursor()\n    curs.execute('''\n      CREATE TABLE patients(PATIENT_ID INT, LASTNAME TEXT);\n    ''')\n    curs.execute('''\n      CREATE TABLE patients_visits(PATIENT_ID INT, VISIT_DATE DATE, SCORE NUMERIC(4,1));\n    ''')\n    conn.commit()\n\ndef fill_tables(conn, fnames):\n    curs = conn.cursor()\n    for fname in fnames:\n        with open(fname) as f:\n            tablename = fname.replace('.csv', '')\n            #\n            csvdata = csv.reader(f)\n            header = next(csvdata)\n            fields = ','.join('?' for _ in header)\n            for row in csvdata:\n                row = [(None if r == '' else r) for r in row]\n                curs.execute(f\"INSERT INTO {tablename} VALUES ({fields});\", row)\n    conn.commit()\n\ndef join_tables_and_group(conn):\n    curs = conn.cursor()\n    curs.execute('''\nCREATE TABLE answer AS\n    SELECT\n    \tpatients.PATIENT_ID,\n    \tpatients.LASTNAME,\n    \tMAX(VISIT_DATE) AS LAST_VISIT,\n    \tSUM(SCORE) AS SCORE_SUM,\n    \tCAST(AVG(SCORE) AS DECIMAL(10,2)) AS SCORE_AVG\n    FROM\n    \tpatients\n    \tLEFT JOIN patients_visits\n    \t\tON patients_visits.PATIENT_ID = patients.PATIENT_ID\n    GROUP BY\n    \tpatients.PATIENT_ID,\n    \tpatients.LASTNAME\n    ORDER BY\n    \tpatients.PATIENT_ID;\n        ''')\n    curs.execute('''\nSELECT * FROM answer;\n        ''')\n    conn.commit()\n    rows = list(curs.fetchall())\n    headers = tuple(d[0] for d in curs.description)\n    return [headers] + rows\n                 \ncreate_table_headers(conn)\nfill_tables(conn, fnames)\nresult = join_tables_and_group(conn)\nfor record in result:\n    print(f\"| {' | '.join(f'{str(r):^10}' for r in record)} |\")\n\n\nOutput:\n| PATIENT_ID |  LASTNAME  | LAST_VISIT | SCORE_SUM  | SCORE_AVG  |\n|    1001    |   Hopper   | 2020-11-19 |    17.4    |    5.8     |\n|    2002    |  Gosling   | 2020-10-08 |    6.8     |    6.8     |\n|    3003    |   Kemeny   | 2020-11-12 |    None    |    None    |\n|    4004    |   Wirth    | 2020-11-05 |    15.4    |    7.7     |\n|    5005    |   Kurtz    |    None    |    None    |    None    |\n", "explain": "Using only standard libraries and input from csv files.\n\nUsing the csv module just to parse inputs; and the sqlite3 module, (which which is also a standard library that comes with the base Python install), to calculate the output.\n(The SQL SELECT statement is modelled on that of the SQL entry elsewhere on this page).\n"}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "C++", "code": "\n\n#include <iostream>\n#include <optional>\n#include <ranges>\n#include <string>\n#include <vector>\n\nusing namespace std;\n\nstruct Patient\n{\n    string ID;\n    string LastName;\n};\n\nstruct Visit\n{\n    string PatientID;\n    string Date;\n    optional<float> Score;\n};\n\nint main(void) \n{\n    auto patients = vector<Patient> {\n        {\"1001\", \"Hopper\"},\n        {\"4004\", \"Wirth\"},\n        {\"3003\", \"Kemeny\"},\n        {\"2002\", \"Gosling\"},\n        {\"5005\", \"Kurtz\"}};\n\n    auto visits = vector<Visit> {    \n        {\"2002\", \"2020-09-10\", 6.8},\n        {\"1001\", \"2020-09-17\", 5.5},\n        {\"4004\", \"2020-09-24\", 8.4},\n        {\"2002\", \"2020-10-08\", },\n        {\"1001\", \"\"          , 6.6},\n        {\"3003\", \"2020-11-12\", },\n        {\"4004\", \"2020-11-05\", 7.0},\n        {\"1001\", \"2020-11-19\", 5.3}};\n\n    // sort the patients by ID\n    sort(patients.begin(), patients.end(), \n         [](const auto& a, const auto&b){ return a.ID < b.ID;});    \n\n    cout << \"| PATIENT_ID | LASTNAME | LAST_VISIT | SCORE_SUM | SCORE_AVG |\\n\";\n    for(const auto& patient : patients)\n    {\n        // loop over all of the patients and determine the fields\n        string lastVisit;\n        float sum = 0;\n        int numScores = 0;\n        \n        // use C++20 ranges to filter the visits by patients\n        auto patientFilter = [&patient](const Visit &v){return v.PatientID == patient.ID;};\n        for(const auto& visit : visits | views::filter( patientFilter ))\n        {\n            if(visit.Score)\n            {\n                sum += *visit.Score;\n                numScores++;\n            }\n            lastVisit = max(lastVisit, visit.Date);\n        }\n        \n        // format the output\n        cout << \"|       \" << patient.ID << \" | \";\n        cout.width(8); cout << patient.LastName << \" | \";\n        cout.width(10); cout << lastVisit << \" | \";\n        if(numScores > 0)\n        {\n            cout.width(9); cout << sum << \" | \";\n            cout.width(9); cout << (sum / float(numScores));\n        }\n        else cout << \"          |          \";\n        cout << \" |\\n\";\n    }\n}\n\n\nOutput:\n| PATIENT_ID | LASTNAME | LAST_VISIT | SCORE_SUM | SCORE_AVG |\n|       1001 |   Hopper | 2020-11-19 |      17.4 |       5.8 |\n|       2002 |  Gosling | 2020-10-08 |       6.8 |       6.8 |\n|       3003 |   Kemeny | 2020-11-12 |           |           |\n|       4004 |    Wirth | 2020-11-05 |      15.4 |       7.7 |\n|       5005 |    Kurtz |            |           |           |\n\n", "explain": "Uses C++20\n"}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "Java", "code": "\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.Comparator;\nimport java.util.DoubleSummaryStatistics;\nimport java.util.List;\n\npublic final class MergeAndAggregateDatasets {\n\n\tpublic static void main(String[] args) {\n\t\tList<Patient> patients = Arrays.asList(\n\t\t\tnew Patient(\"1001\", \"Hopper\"),\n\t\t\tnew Patient(\"4004\", \"Wirth\"),\n\t\t\tnew Patient(\"3003\", \"Kemeny\"),\n\t\t\tnew Patient(\"2002\", \"Gosling\"),\n\t\t\tnew Patient(\"5005\", \"Kurtz\") );\n\n\t\tList<Visit> visits = Arrays.asList(\t\t\t\t\n\t\t    new Visit(\"2002\", \"2020-09-10\", 6.8),\n\t\t    new Visit(\"1001\", \"2020-09-17\", 5.5),\n\t\t    new Visit(\"4004\", \"2020-09-24\", 8.4),\n\t\t    new Visit(\"2002\", \"2020-10-08\", null),\n\t\t    new Visit(\"1001\", \"\"          , 6.6),\n\t\t    new Visit(\"3003\", \"2020-11-12\", null),\n\t\t    new Visit(\"4004\", \"2020-11-05\", 7.0),\n\t\t    new Visit(\"1001\", \"2020-11-19\", 5.3) );\n\t\t\n\t\tCollections.sort(patients, Comparator.comparing(Patient::patientID));\t\t\n\t\tSystem.out.println(\"| PATIENT_ID | LASTNAME | LAST_VISIT | SCORE_SUM | SCORE_AVG |\");\t\t\n\t    for ( Patient patient : patients ) {\t    \t\n\t    \tList<Visit> patientVisits = visits.stream().filter( v -> v.visitID == patient.patientID() ).toList();\n\t    \tString lastVisit = patientVisits.stream()\n\t    \t\t.map( v -> v.visitDate ).max(Comparator.naturalOrder()).orElseGet( () -> \"   None   \" );\t    \t\n\t    \tDoubleSummaryStatistics statistics = patientVisits.stream()\n\t    \t\t.filter( v -> v.score != null ).mapToDouble(Visit::score).summaryStatistics();\t    \t\t    \t\n\t    \tdouble scoreSum = statistics.getSum();\n\t    \tdouble scoreAverage = statistics.getAverage();\t    \t\n\t    \tString patientDetails = String.format(\"%12s%11s%13s%12.2f%12.2f\", \n\t    \t\tpatient.patientID, patient.lastName, lastVisit, scoreSum, scoreAverage);\t    \t\n\t    \tSystem.out.println(patientDetails);\n\t    }\n\n        private static record Patient(String patientID, String lastName) {};\n\t    private static record Visit(String visitID, String visitDate, Double score) {};\n\n\t} \n\n}\n\n\nOutput:\n| PATIENT_ID | LASTNAME | LAST_VISIT | SCORE_SUM | SCORE_AVG |\n        1001     Hopper   2020-11-19       17.40        5.80\n        2002    Gosling   2020-10-08        6.80        6.80\n        3003     Kemeny   2020-11-12        0.00        0.00\n        4004      Wirth   2020-11-05       15.40        7.70\n        5005      Kurtz      None           0.00        0.00\n\n", "explain": ""}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "C#", "code": "\nusing System;\nusing System.Collections.Generic;\nusing System.Globalization;\nusing System.Linq;\nusing System.Runtime.Serialization;\n\npublic static class MergeAndAggregateDatasets\n{\n    public static void Main()\n    {\n        string patientsCsv = @\"\nPATIENT_ID,LASTNAME\n1001,Hopper\n4004,Wirth\n3003,Kemeny\n2002,Gosling\n5005,Kurtz\";\n\n        string visitsCsv = @\"\nPATIENT_ID,VISIT_DATE,SCORE\n2002,2020-09-10,6.8\n1001,2020-09-17,5.5\n4004,2020-09-24,8.4\n2002,2020-10-08,\n1001,,6.6\n3003,2020-11-12,\n4004,2020-11-05,7.0\n1001,2020-11-19,5.3\";\n\n        string format = \"yyyy-MM-dd\";\n        var formatProvider = new DateTimeFormat(format).FormatProvider;\n\n        var patients = ParseCsv(\n            patientsCsv.Split(Environment.NewLine, StringSplitOptions.RemoveEmptyEntries),\n            line => (PatientId: int.Parse(line[0]), LastName: line[1]));\n\n        var visits = ParseCsv(\n            visitsCsv.Split(Environment.NewLine, StringSplitOptions.RemoveEmptyEntries),\n            line => (\n                PatientId: int.Parse(line[0]),\n                VisitDate: DateTime.TryParse(line[1], formatProvider, DateTimeStyles.None, out var date) ? date : default(DateTime?),\n                Score: double.TryParse(line[2], out double score) ? score : default(double?)\n            )\n        );\n\n        var results =\n            patients.GroupJoin(visits,\n                p => p.PatientId,\n                v => v.PatientId,\n                (p, vs) => (\n                    p.PatientId,\n                    p.LastName,\n                    LastVisit: vs.Max(v => v.VisitDate),\n                    ScoreSum: vs.Sum(v => v.Score),\n                    ScoreAvg: vs.Average(v => v.Score)\n                )\n            ).OrderBy(r => r.PatientId);\n\n        Console.WriteLine(\"| PATIENT_ID | LASTNAME | LAST_VISIT | SCORE_SUM | SCORE_AVG |\");\n        foreach (var r in results) {\n            Console.WriteLine($\"| {r.PatientId,-10} | {r.LastName,-8} | {r.LastVisit?.ToString(format)\u00a0?? \"\",-10} | {r.ScoreSum,9} | {r.ScoreAvg,9} |\");\n        }\n    }\n\n    private static IEnumerable<T> ParseCsv<T>(string[] contents, Func<string[], T> constructor)\n    {\n        for (int i = 1; i < contents.Length; i++) {\n            var line = contents[i].Split(',');\n            yield return constructor(line);\n        }\n    }\n\n}\n\n\nOutput:\n| PATIENT_ID | LASTNAME | LAST_VISIT | SCORE_SUM | SCORE_AVG |\n| 1001       | Hopper   | 2020-11-19 |      17.4 |       5.8 |\n| 2002       | Gosling  | 2020-10-08 |       6.8 |       6.8 |\n| 3003       | Kemeny   | 2020-11-12 |         0 |           |\n| 4004       | Wirth    | 2020-11-05 |      15.4 |       7.7 |\n| 5005       | Kurtz    |            |         0 |           |\n", "explain": ""}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "SQL", "code": "\n-- drop tables\nDROP TABLE IF EXISTS tmp_patients;\nDROP TABLE IF EXISTS tmp_visits;\n\n-- create tables\nCREATE TABLE tmp_patients(\n\tPATIENT_ID INT,\n\tLASTNAME VARCHAR(20)\n);\n\nCREATE TABLE tmp_visits(\n\tPATIENT_ID INT,\n\tVISIT_DATE DATE,\n\tSCORE NUMERIC(4,1)\n);\n\n-- load data from csv files\n/*\n-- Note: LOAD DATA LOCAL requires `local-infile` enabled on both the client and server else you get error \"#1148 command is not allowed..\"\nLOAD DATA LOCAL INFILE '/home/csv/patients.csv' INTO TABLE `tmp_patients` FIELDS TERMINATED BY ',' LINES TERMINATED BY '\\n' IGNORE 1 LINES;\nLOAD DATA LOCAL INFILE '/home/csv/visits.csv' INTO TABLE `tmp_visits` FIELDS TERMINATED BY ',' LINES TERMINATED BY '\\n' IGNORE 1 LINES;\n*/\n\n-- load data hard coded\nINSERT INTO tmp_patients(PATIENT_ID, LASTNAME)\nVALUES\n(1001, 'Hopper'),\n(4004, 'Wirth'),\n(3003, 'Kemeny'),\n(2002, 'Gosling'),\n(5005, 'Kurtz');\n\nINSERT INTO tmp_visits(PATIENT_ID, VISIT_DATE, SCORE)\nVALUES\n(2002, '2020-09-10', 6.8),\n(1001, '2020-09-17', 5.5),\n(4004, '2020-09-24', 8.4),\n(2002, '2020-10-08', NULL),\n(1001, NULL, 6.6),\n(3003, '2020-11-12', NULL),\n(4004, '2020-11-05', 7.0),\n(1001, '2020-11-19', 5.3);\n\n-- join tables and group\nSELECT\n\tp.PATIENT_ID,\n\tp.LASTNAME,\n\tMAX(VISIT_DATE) AS LAST_VISIT,\n\tSUM(SCORE) AS SCORE_SUM,\n\tCAST(AVG(SCORE) AS DECIMAL(10,2)) AS SCORE_AVG\nFROM\n\ttmp_patients p\n\tLEFT JOIN tmp_visits v\n\t\tON v.PATIENT_ID = p.PATIENT_ID\nGROUP BY\n\tp.PATIENT_ID,\n\tp.LASTNAME\nORDER BY\n\tp.PATIENT_ID;\n\n\nOutput:\nPATIENT_ID  LASTNAME  LAST_VISIT  SCORE_SUM  SCORE_AVG\n1001        Hopper    2020-11-19       17.4       5.80\n2002        Gosling   2020-10-08        6.8       6.80\n3003        Kemeny    2020-11-12       NULL       NULL\n4004        Wirth     2020-11-05       15.4       7.70\n5005        Kurtz     NULL             NULL       NULL\n\n", "explain": ""}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "Go", "code": "\nTranslation of: Wren\npackage main\n\nimport (\n    \"fmt\"\n    \"math\"\n    \"sort\"\n)\n\ntype Patient struct {\n    id       int\n    lastName string\n}\n\n// maps an id to a lastname\nvar patientDir = make(map[int]string)\n\n// maintains a sorted list of ids\nvar patientIds []int\n\nfunc patientNew(id int, lastName string) Patient {\n    patientDir[id] = lastName\n    patientIds = append(patientIds, id)\n    sort.Ints(patientIds)\n    return Patient{id, lastName}\n}\n\ntype DS struct {\n    dates  []string\n    scores []float64\n}\n\ntype Visit struct {\n    id    int\n    date  string\n    score float64\n}\n\n// maps an id to lists of dates and scores\nvar visitDir = make(map[int]DS)\n\nfunc visitNew(id int, date string, score float64) Visit {\n    if date == \"\" {\n        date = \"0000-00-00\"\n    }\n    v, ok := visitDir[id]\n    if ok {\n        v.dates = append(v.dates, date)\n        v.scores = append(v.scores, score)\n        visitDir[id] = DS{v.dates, v.scores}\n    } else {\n        visitDir[id] = DS{[]string{date}, []float64{score}}\n    }\n    return Visit{id, date, score}\n}\n\ntype Merge struct{ id int }\n\nfunc (m Merge) lastName() string  { return patientDir[m.id] }\nfunc (m Merge) dates() []string   { return visitDir[m.id].dates }\nfunc (m Merge) scores() []float64 { return visitDir[m.id].scores }\n\nfunc (m Merge) lastVisit() string {\n    dates := m.dates()\n    dates2 := make([]string, len(dates))\n    copy(dates2, dates)\n    sort.Strings(dates2)\n    return dates2[len(dates2)-1]\n}\n\nfunc (m Merge) scoreSum() float64 {\n    sum := 0.0\n    for _, score := range m.scores() {\n        if score != -1 {\n            sum += score\n        }\n    }\n    return sum\n}\n\nfunc (m Merge) scoreAvg() float64 {\n    count := 0\n    for _, score := range m.scores() {\n        if score != -1 {\n            count++\n        }\n    }\n    return m.scoreSum() / float64(count)\n}\n\nfunc mergePrint(merges []Merge) {\n    fmt.Println(\"| PATIENT_ID | LASTNAME | LAST_VISIT | SCORE_SUM | SCORE_AVG |\")\n    f := \"| %d       |\u00a0%-7s  | %s | %4s      | %4s      |\\n\"\n    for _, m := range merges {\n        _, ok := visitDir[m.id]\n        if ok {\n            lv := m.lastVisit()\n            if lv == \"0000-00-00\" {\n                lv = \"          \"\n            }\n            scoreSum := m.scoreSum()\n            ss := fmt.Sprintf(\"%4.1f\", scoreSum)\n            if scoreSum == 0 {\n                ss = \"    \"\n            }\n            scoreAvg := m.scoreAvg()\n            sa := \"    \"\n            if !math.IsNaN(scoreAvg) {\n                sa = fmt.Sprintf(\"%4.2f\", scoreAvg)\n            }\n            fmt.Printf(f, m.id, m.lastName(), lv, ss, sa)\n        } else {\n            fmt.Printf(f, m.id, m.lastName(), \"          \", \"    \", \"    \")\n        }\n    }\n}\n\nfunc main() {\n    patientNew(1001, \"Hopper\")\n    patientNew(4004, \"Wirth\")\n    patientNew(3003, \"Kemeny\")\n    patientNew(2002, \"Gosling\")\n    patientNew(5005, \"Kurtz\")\n\n    visitNew(2002, \"2020-09-10\", 6.8)\n    visitNew(1001, \"2020-09-17\", 5.5)\n    visitNew(4004, \"2020-09-24\", 8.4)\n    visitNew(2002, \"2020-10-08\", -1) // -1 signifies no score\n    visitNew(1001, \"\", 6.6)          // \"\" signifies no date\n    visitNew(3003, \"2020-11-12\", -1)\n    visitNew(4004, \"2020-11-05\", 7.0)\n    visitNew(1001, \"2020-11-19\", 5.3)\n\n    merges := make([]Merge, len(patientIds))\n    for i, id := range patientIds {\n        merges[i] = Merge{id}\n    }\n    mergePrint(merges)\n}\n\n\nOutput:\n| PATIENT_ID | LASTNAME | LAST_VISIT | SCORE_SUM | SCORE_AVG |\n| 1001       | Hopper   | 2020-11-19 | 17.4      | 5.80      |\n| 2002       | Gosling  | 2020-10-08 |  6.8      | 6.80      |\n| 3003       | Kemeny   | 2020-11-12 |           |           |\n| 4004       | Wirth    | 2020-11-05 | 15.4      | 7.70      |\n| 5005       | Kurtz    |            |           |           |\n\n", "explain": ""}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "R", "code": "\n# load data from csv files\n# setwd(\"C:\\Temp\\csv\\\")\n# df_patient <- read.csv(file=\"patients.csv\", header = TRUE, sep = \",\")\n# df_visits <- read.csv(file=\"visits.csv\", header = TRUE, sep = \",\", dec = \".\", colClasses=c(\"character\",\"character\",\"numeric\"))\n\n# load data hard coded, create data frames\ndf_patient <- read.table(text = \"\nPATIENT_ID,LASTNAME\n1001,Hopper\n4004,Wirth\n3003,Kemeny\n2002,Gosling\n5005,Kurtz\n\", header = TRUE, sep = \",\") #  character fields so no need for extra parameters colClasses etc.\n\ndf_visits <- read.table(text = \"\nPATIENT_ID,VISIT_DATE,SCORE\n2002,2020-09-10,6.8\n1001,2020-09-17,5.5\n4004,2020-09-24,8.4\n2002,2020-10-08,\n1001,,6.6\n3003,2020-11-12,\n4004,2020-11-05,7.0\n1001,2020-11-19,5.3\n\", header = TRUE, dec = \".\", sep = \",\", colClasses=c(\"character\",\"character\",\"numeric\"))\n\n# aggregate visit date and scores\ndf_agg <- data.frame(\n  cbind(\n    PATIENT_ID = names(tapply(df_visits$VISIT_DATE, list(df_visits$PATIENT_ID), max, na.rm=TRUE)),\n    last_visit = tapply(df_visits$VISIT_DATE, list(df_visits$PATIENT_ID), max, na.rm=TRUE),\n    score_sum = tapply(df_visits$SCORE, list(df_visits$PATIENT_ID), sum, na.rm=TRUE),\n    score_avg = tapply(df_visits$SCORE, list(df_visits$PATIENT_ID), mean, na.rm=TRUE)\n  )\n) \n\n# merge patients and aggregate dataset\n# all.x = all the non matching cases of df_patient are appended to the result as well (i.e. 'left join')\ndf_result <- merge(df_patient, df_agg, by = 'PATIENT_ID', all.x = TRUE)\n\nprint(df_result)\n\n\nOutput:\n  PATIENT_ID LASTNAME last_visit score_sum score_avg\n1       1001   Hopper 2020-11-19      17.4       5.8\n2       2002  Gosling 2020-10-08       6.8       6.8\n3       3003   Kemeny 2020-11-12         0       NaN\n4       4004    Wirth 2020-11-05      15.4       7.7\n5       5005    Kurtz       <NA>      <NA>      <NA>\n\n", "explain": ""}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "Julia", "code": "\nTranslation of: Python\nusing CSV, DataFrames, Statistics\n\n# load data from csv files\n#df_patients = CSV.read(\"patients.csv\", DataFrame)\n#df_visits = CSV.read(\"visits.csv\", DataFrame)\n\n# create DataFrames from text that is hard coded, so use IOBuffer(String) as input\nstr_patients = IOBuffer(\"\"\"PATIENT_ID,LASTNAME\n1001,Hopper\n4004,Wirth\n3003,Kemeny\n2002,Gosling\n5005,Kurtz\n\"\"\")\ndf_patients = CSV.read(str_patients, DataFrame)\nstr_visits = IOBuffer(\"\"\"PATIENT_ID,VISIT_DATE,SCORE\n2002,2020-09-10,6.8\n1001,2020-09-17,5.5\n4004,2020-09-24,8.4\n2002,2020-10-08,\n1001,,6.6\n3003,2020-11-12,\n4004,2020-11-05,7.0\n1001,2020-11-19,5.3\n\"\"\")\ndf_visits = CSV.read(str_visits, DataFrame)\n\n# merge on PATIENT_ID, using an :outer join or we lose Kurtz, who has no data, sort by ID\ndf_merge = sort(join(df_patients, df_visits, on=\"PATIENT_ID\", kind=:outer), (:PATIENT_ID,))\n\nfnonmissing(a, f) = isempty(a) ? [] : isempty(skipmissing(a)) ? a[1] : f(skipmissing(a))\n\n# group by patient id / last name and then aggregate to get latest visit and mean score\ndf_result = by(df_merge, [:PATIENT_ID, :LASTNAME]) do df\n    DataFrame(LATEST_VISIT = fnonmissing(df[:VISIT_DATE], maximum),\n              SUM_SCORE = fnonmissing(df[:SCORE], sum),\n              MEAN_SCORE = fnonmissing(df[:SCORE], mean))\nend\nprintln(df_result)\n\nOutput:\n5\u00d75 DataFrame\n\u2502 Row \u2502 PATIENT_ID \u2502 LASTNAME \u2502 LATEST_VISIT \u2502 SUM_SCORE \u2502 MEAN_SCORE \u2502\n\u2502     \u2502 Int64?     \u2502 String?  \u2502 Dates.Date?  \u2502 Float64?  \u2502 Float64?   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1   \u2502 1001       \u2502 Hopper   \u2502 2020-11-19   \u2502 17.4      \u2502 5.8        \u2502\n\u2502 2   \u2502 2002       \u2502 Gosling  \u2502 2020-10-08   \u2502 6.8       \u2502 6.8        \u2502\n\u2502 3   \u2502 3003       \u2502 Kemeny   \u2502 2020-11-12   \u2502 missing   \u2502 missing    \u2502\n\u2502 4   \u2502 4004       \u2502 Wirth    \u2502 2020-11-05   \u2502 15.4      \u2502 7.7        \u2502\n\u2502 5   \u2502 5005       \u2502 Kurtz    \u2502 missing      \u2502 missing   \u2502 missing    \u2502\n\n", "explain": ""}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "SAS", "code": "\n  %let datefmt=E8601DA10.;\n  data patient;\n      infile \"patient.csv\" dsd dlm=',';\n      attrib\n          id length=4\n          lastname length=$10; \n      input id lastname;\n  data visit;\n      infile \"visit.csv\" dsd dlm=',';\n      attrib\n          id length=4\n          date informat=&datefmt format=&datefmt\n          score length=8; \n      input id date score;\n  proc sql;\n      select * from \n          (select id, max(date) format=&datefmt as max_date, sum(score) as sum_score,\n          \tavg(score) as avg_score from visit group by id)\n          natural right join patient\n          order by id;\n\n\nOutput:\n:       id  lastname      max_date  sum_score  avg_score\n: ------------------------------------------------------\n:     1001  Hopper      2020-11-19       17.4        5.8\n:     2002  Gosling     2020-10-08        6.8        6.8\n:     3003  Kemeny      2020-11-12          .          .\n:     4004  Wirth       2020-11-05       15.4        7.7\n:     5005  Kurtz                .          .          .\n", "explain": ""}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "Perl", "code": "\n\n#!/usr/bin/perl\nmy $fmt = '|\u00a0%-11s' x 5 . \"|\\n\";\nprintf $fmt, qw( PATIENT_ID LASTNAME LAST_VISIT SCORE_SUM SCORE_AVG);\nmy ($names, $visits) = do { local $/; split /^\\n/m, <DATA> };\nmy %score;\nfor ( $visits =~ /^\\d.*/gm )\n  {\n  my ($id, undef, $score) = split /,/;\n  $score{$id} //= ['', ''];\n  $score and $score{$id}[0]++, $score{$id}[1] += $score;\n  }\nfor ( sort $names =~ /^\\d.*/gm )\n  {\n  my ($id, $name) = split /,/;\n  printf $fmt, $id, $name, ( sort $visits =~ /^$id,(.*?),/gm, '' )[-1],\n    $score{$id}[0]\n      ? ( $score{$id}[1], $score{$id}[1] / $score{$id}[0])\n      : ('', '');\n  }\n\n__DATA__\nPATIENT_ID,LASTNAME\n1001,Hopper\n4004,Wirth\n3003,Kemeny\n2002,Gosling\n5005,Kurtz\n\nPATIENT_ID,VISIT_DATE,SCORE\n2002,2020-09-10,6.8\n1001,2020-09-17,5.5\n4004,2020-09-24,8.4\n2002,2020-10-08,\n1001,,6.6\n3003,2020-11-12,\n4004,2020-11-05,7.0\n1001,2020-11-19,5.3\n\n\nOutput:\n| PATIENT_ID | LASTNAME   | LAST_VISIT | SCORE_SUM  | SCORE_AVG  |\n| 1001       | Hopper     | 2020-11-19 | 17.4       | 5.8        |\n| 2002       | Gosling    | 2020-10-08 | 6.8        | 6.8        |\n| 3003       | Kemeny     | 2020-11-12 |            |            |\n| 4004       | Wirth      | 2020-11-05 | 15.4       | 7.7        |\n| 5005       | Kurtz      |            |            |            |\n\n", "explain": "Weird requirement: \"Use the most common libraries only when built-in functionality is not sufficient.\"\nNot even a \"use strict;\"\u00a0:)\n"}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "Prolog", "code": "\n\npatient(1001,'Hopper').\npatient(4004,'Wirth').\npatient(3003,'Kemeny').\npatient(2002,'Gosling').\npatient(5005,'Kurtz').\n \nvisit(2002,'2020-09-10',6.8).\nvisit(1001,'2020-09-17',5.5).\nvisit(4004,'2020-09-24',8.4).\nvisit(2002,'2020-10-08',nan).\nvisit(1001,'',6.6).\nvisit(3003,'2020-11-12',nan).\nvisit(4004,'2020-11-05',7.0).\nvisit(1001,'2020-11-19',5.3).\n\nsummaryDates(Id, Lastname, LastDate) :- \n     aggregate(max(Ts),\n\t       Score^Date^(visit(Id, Date, Score), Date \\= '', parse_time(Date, iso_8601, Ts)),\n\t       MaxTs),\n     format_time(atom(LastDate), '%Y-%m-%d', MaxTs),\n     patient(Id,Lastname).\n\nsummaryScores(Id, Lastname, Sum, Mean) :- \n     aggregate(r(sum(Score),count), Date^(visit(Id, Date, Score), Score \\= nan), r(Sum,Count)), \n     patient(Id,Lastname),\n     Mean is Sum/Count.\n\ntest :-\n    summaryDates(Id, Lastname, LastDate),\n    writeln(summaryDates(Id, Lastname, LastDate)),\n    fail.\n\ntest :-\n    summaryScores(Id, Lastname, ScoreSum, ScoreMean),\n    writeln(summaryScores(Id, Lastname, ScoreSum, ScoreMean)),\n    fail.\n\n\nOutput:\nsummaryDates(1001,Hopper,2020-11-19)\nsummaryDates(2002,Gosling,2020-10-08)\nsummaryDates(3003,Kemeny,2020-11-12)\nsummaryDates(4004,Wirth,2020-11-05)\nsummaryScores(1001,Hopper,17.4,5.8)\nsummaryScores(2002,Gosling,6.8,6.8)\nsummaryScores(4004,Wirth,15.4,7.7)\nfalse.\n\n:- import bagMax/2, bagCount/2, bagSum/2, bagReduce/4 from aggregs.\n:- import julian_date/7, date_string/3 from iso8601.\n:- import load_csv/2, add_cvt_type_hook/2 from proc_files.\n\n?- add_cvt_type_hook(date,date_converter(_,_)).\n\ndate_converter(Atom,Date) :- date_string('YYYY-MM-DD',Date,Atom).\n\n:- load_csv('visit.csv',visit(integer,date,float)).\n:- load_csv('patient.csv',patient(integer,atom)).\n\nis_nan(Number) :- X is Number, X =\\= Number.\n\nsummaryDates(Id, Lastname, LastDate) :-\n    bagMax(date_number(Id), LastDateNumber),\n    patient(Id,Lastname),\n    julian_date(LastDateNumber, Y, M, D, _, _, _),\n    date_converter(LastDate, date(Y,M,D)).\n\nsummaryScores(Id, Lastname, Sum, Mean) :- \n    bagSum(scores(Id), Sum),\n    bagCount(scores(Id), Count),\n    Mean is Sum/Count,\n    patient(Id,Lastname).\n\ntest :-\n    summaryDates(Id,Lastname,LastDate),\n    writeln(summaryDates(Id,Lastname,LastDate)), fail.\n\ntest :-\n    summaryScores(Id, Lastname, ScoreSum, ScoreMean),\n    writeln(summaryScores(Id, Lastname, ScoreSum, ScoreMean)), fail.\n\n/* Put hilog declarations together */\n\ndate_number(Id)(Number) :-\n    visit(Id, date(Y,M,D), _), \n    julian_date(Number, Y, M, D, _, _, _).\n\t\t   \nscores(Id)(Score) :-\n    visit(Id, _, Score),\n    \\+is_nan(Score).\n\n:- hilog maximum.\nmaximum(X,Y,Z) :- X @> Y -> Z=X ; Z=Y.\n:- hilog sum.\nsum(X,Y,Z) :- Z is X+Y.\n:- hilog successor.\nsuccessor(X,_Y,Z) :- Z is X+1.\n\n", "explain": "Implemented using SWI Prolog:\nImplemented using XSB Prolog (which allows for user-defined aggregates):\n"}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "Haskell", "code": "\nReading and merging[edit]\n\nimport Data.List\nimport Data.Maybe\nimport System.IO (readFile)\nimport Text.Read (readMaybe)\nimport Control.Applicative ((<|>))\n\n------------------------------------------------------------\n\nnewtype DB = DB { entries :: [Patient] }\n  deriving Show\n\ninstance Semigroup DB where\n  DB a <> DB b = normalize $ a <> b\n\ninstance Monoid DB where\n  mempty = DB []\n\nnormalize :: [Patient] -> DB\nnormalize = DB\n            . map mconcat \n            . groupBy (\\x y -> pid x == pid y)\n            . sortOn pid\n \n------------------------------------------------------------\n\ndata Patient = Patient { pid :: String\n                       , name :: Maybe String\n                       , visits :: [String]\n                       , scores :: [Float] }\n  deriving Show\n\ninstance Semigroup Patient where\n  Patient p1 n1 v1 s1 <> Patient p2 n2 v2 s2 =\n    Patient (fromJust $ Just p1 <|> Just p2)\n            (n1 <|> n2)\n            (v1 <|> v2)\n            (s1 <|> s2)\n\ninstance Monoid Patient where\n  mempty = Patient mempty mempty mempty mempty\n    \n------------------------------------------------------------\n\nreadDB :: String  -> DB\nreadDB = normalize\n         . mapMaybe readPatient\n         . readCSV\n\nreadPatient r = do\n  i <- lookup \"PATIENT_ID\" r\n  let n = lookup \"LASTNAME\" r\n  let d = lookup \"VISIT_DATE\" r >>= readDate\n  let s = lookup \"SCORE\" r >>= readMaybe\n  return $ Patient i n (maybeToList d) (maybeToList s)\n  where\n    readDate [] = Nothing\n    readDate d = Just d\n\nreadCSV :: String -> [(String, String)]\nreadCSV txt = zip header <$> body\n  where\n    header:body = splitBy ',' <$> lines txt\n    splitBy ch = unfoldr go\n      where\n        go [] = Nothing\n        go s  = Just $ drop 1 <$> span (/= ch) s\n\nlet patients = readDB <$> readFile \"patients.csv\"\n*Main> let visits = readDB <$> readFile \"visits.csv\" \n\n*Main> mapM_ print . entries =<< patients\nPatient {pid = \"1001\", name = Just \"Hopper\", visits = [], scores = []}\nPatient {pid = \"2002\", name = Just \"Gosling\", visits = [], scores = []}\nPatient {pid = \"3003\", name = Just \"Kemeny\", visits = [], scores = []}\nPatient {pid = \"4004\", name = Just \"Wirth\", visits = [], scores = []}\nPatient {pid = \"5005\", name = Just \"Kurtz\", visits = [], scores = []}\n\n*Main> mapM_ print . entries =<< visits\nPatient {pid = \"1001\", name = Nothing, visits = [\"2020-09-17\",\"2020-11-19\"], scores = [5.3,6.6,5.5]}\nPatient {pid = \"2002\", name = Nothing, visits = [\"2020-09-10\",\"2020-10-08\"], scores = [6.8]}\nPatient {pid = \"3003\", name = Nothing, visits = [\"2020-11-12\"], scores = []}\nPatient {pid = \"4004\", name = Nothing, visits = [\"2020-09-24\",\"2020-11-05\"], scores = [7.0,8.4]}\n\n*Main> mapM_ print . entries =<< patients <> visits\nPatient {pid = \"1001\", name = Just \"Hopper\", visits = [\"2020-09-17\",\"2020-11-19\"], scores = [5.3,6.6,5.5]}\nPatient {pid = \"2002\", name = Just \"Gosling\", visits = [\"2020-09-10\",\"2020-10-08\"], scores = [6.8]}\nPatient {pid = \"3003\", name = Just \"Kemeny\", visits = [\"2020-11-12\"], scores = []}\nPatient {pid = \"4004\", name = Just \"Wirth\", visits = [\"2020-09-24\",\"2020-11-05\"], scores = [7.0,8.4]}\nPatient {pid = \"5005\", name = Just \"Kurtz\", visits = [], scores = []}\nPretty tabulation[edit]\ntabulateDB (DB ps) header cols = intercalate \"|\" <$> body\n  where\n    body = transpose $ zipWith pad width table\n    table = transpose $ header : map showPatient ps\n    showPatient p = sequence cols p\n    width = maximum . map length <$> table\n    pad n col = (' ' :) . take (n+1) . (++ repeat ' ') <$> col\n\nmain = do\n  a <- readDB <$> readFile \"patients.csv\"\n  b <- readDB <$> readFile \"visits.csv\"\n  mapM_ putStrLn $ tabulateDB (a <> b) header fields\n  where\n    header = [ \"PATIENT_ID\", \"LASTNAME\", \"VISIT_DATE\"\n             , \"SCORES SUM\",\"SCORES AVG\"]\n    fields = [ pid\n             , fromMaybe [] . name\n             , \\p -> case visits p of {[] -> []; l -> last l}\n             , \\p -> case scores p of {[] -> []; s -> show (sum s)}\n             , \\p -> case scores p of {[] -> []; s -> show (mean s)} ]\n\n    mean lst = sum lst / genericLength lst\n\n*Main> main\n PATIENT_ID | LASTNAME | VISIT_DATE | SCORES SUM | SCORES AVG \n 1001       | Hopper   | 2020-11-19 | 17.4       | 5.7999997  \n 2002       | Gosling  | 2020-10-08 | 6.8        | 6.8        \n 3003       | Kemeny   | 2020-11-12 |            |            \n 4004       | Wirth    | 2020-11-05 | 15.4       | 7.7        \n 5005       | Kurtz    |            |            |            \n", "explain": "Merging of fields and databases is defined as a monoid operation for corresponding types.\n"}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "F#", "code": "\n\n// Merge and aggregate datasets. Nigel Galloway: January 6th., 2021\nlet rFile(fName)=seq{use n=System.IO.File.OpenText(fName)\n                     n.ReadLine() |> ignore\n                     while not n.EndOfStream do yield n.ReadLine().Split [|','|]}\nlet N=rFile(\"file1.txt\") |> Seq.sort\nlet G=rFile(\"file2.txt\") |> Seq.groupBy(fun n->n.[0]) |> Map.ofSeq\nlet fN n i g e l=printfn \"|\u00a0%-10s |\u00a0%-8s | %10s | \u00a0%-9s |\u00a0%-9s |\" n i g e l \nlet fG n g=let z=G.[n]|>Seq.sumBy(fun n->try float n.[2] with :? System.FormatException->0.0)\n           fN n g (G.[n]|>Seq.sort|>Seq.last).[1] (if z=0.0 then \"\" else string z) (if z=0.0 then \"\" else string(z/(float(Seq.length G.[n]))))\n\n\nOutput:\nprintfn \"| PATIENT_ID | LASTNAME | LAST_VISIT |  SCORE_SUM | SCORE_AVG |\"\nN|>Seq.iter(fun n->match G.ContainsKey n.[0] with true->fG n.[0] n.[1] |_->fN n.[0] n.[1] \"\" \"\" \"\")\n\n| PATIENT_ID | LASTNAME | LAST_VISIT |  SCORE_SUM | SCORE_AVG |\n| 1001       | Hopper   | 2020-11-19 |  17.4      | 5.8       |\n| 2002       | Gosling  | 2020-10-08 |  6.8       | 3.4       |\n| 3003       | Kemeny   | 2020-11-12 |            |           |\n| 4004       | Wirth    | 2020-11-05 |  15.4      | 7.7       |\n| 5005       | Kurtz    |            |            |           |\n\n", "explain": "Note that the scores are right justified to copy the task description. It would be more natural to leave them right justified.\n"}, {"task_name": "Merge and aggregate datasets", "task_url": "https://rosettacode.org/wiki/Merge_and_aggregate_datasets", "task_cat": "Data Structures", "lang": "AWK", "code": "\n# syntax: GAWK -f MERGE_AND_AGGREGATE_DATASETS.AWK RC-PATIENTS.CSV RC-VISITS.CSV\n# files may appear in any order\n#\n# sorting:\n#   PROCINFO[\"sorted_in\"] is used by GAWK\n#   SORTTYPE is used by Thompson Automation's TAWK\n#\n{ # printf(\"%s %s\\n\",FILENAME,$0) # print input\n    split($0,arr,\",\")\n    if (FNR == 1) {\n      file = (arr[2] == \"LASTNAME\") ? \"patients\" : \"visits\"\n      next\n    }\n    patient_id_arr[key] = key = arr[1]\n    if (file == \"patients\") {\n      lastname_arr[key] = arr[2]\n    }\n    else if (file == \"visits\") {\n      if (arr[2] > visit_date_arr[key]) {\n        visit_date_arr[key] = arr[2]\n      }\n      if (arr[3] != \"\") {\n        score_arr[key] += arr[3]\n        score_count_arr[key]++\n      }\n    }\n}\nEND {\n    print(\"\")\n    PROCINFO[\"sorted_in\"] = \"@ind_str_asc\" ; SORTTYPE = 1\n    fmt = \"%-10s\u00a0%-10s\u00a0%-10s %9s %9s %6s\\n\"\n    printf(fmt,\"patient_id\",\"lastname\",\"last_visit\",\"score_sum\",\"score_avg\",\"scores\")\n    for (i in patient_id_arr) {\n      avg = (score_count_arr[i] > 0) ? score_arr[i] / score_count_arr[i] : \"\"\n      printf(fmt,patient_id_arr[i],lastname_arr[i],visit_date_arr[i],score_arr[i],avg,score_count_arr[i]+0)\n    }\n    exit(0)\n}\n\n\nOutput:\npatient_id lastname   last_visit score_sum score_avg scores\n1001       Hopper     2020-11-19      17.4       5.8      3\n2002       Gosling    2020-10-08       6.8       6.8      1\n3003       Kemeny     2020-11-12                          0\n4004       Wirth      2020-11-05      15.4       7.7      2\n5005       Kurtz                                          0\n\n", "explain": ""}]